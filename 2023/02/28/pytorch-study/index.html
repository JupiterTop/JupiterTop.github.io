<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>pytorch study | wBlog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  
  
  
    <link rel="alternate" href="/atom.xml" title="wBlog" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
    
<link rel="stylesheet" href="/localshare/css/share.css">

  
  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">wBlog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        
          <a class="main-nav-link" href="/."><i class="fa fa-home"></i> Home</a>
        
          <a class="main-nav-link" href="/archives/"><i class="fa fa-archive"></i> Archive</a>
        
          <a class="main-nav-link" href="/about/"><i class="fa fa-user"></i> About</a>
        
          <a class="main-nav-link" href="/atom.xml"><i class="fa fa-rss"></i> RSS</a>
        
      </nav>
    </div>
    <div id="search-form">
      <div id="result-mask" class="hide"></div>
      <label><input id="search-key" type="text" autocomplete="off" placeholder="search"></label>
      <div id="result-wrap" class="hide">
        <div id="search-result"></div>
      </div>
      <div class="hide">
        <template id="search-tpl">
          <div class="item">
            <a href="/{path}" title="{title}">
              <div class="title">{title}</div>
              <div class="time">{date}</div>
              <div class="tags">{tags}</div>
            </a>
          </div>
        </template>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-pytorch-study" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      pytorch study
    </h1>
  


      </header>
    
    <div class="article-meta">
      
      <span class="article-date">
  <i class="fa fa-date"></i>
  <time class="dt-published" datetime="2023-02-28T05:52:25.000Z" itemprop="datePublished">2023年02月28日</time>
</span>
      
      
        <span class="article-views">
  <i class="fa fa-views"></i>
  <i id="busuanzi_container_page_pv">
      <i id="busuanzi_value_page_pv"></i>
  </i>
</span>
      
      
<a href="/2023/02/28/pytorch-study/#comments" class="article-comment-link">
  
    
    
    
    
    
  
  <i class="fa fa-commt"></i>
  Guestbook
</a>


      
    </div>
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="PyTorch深度学习实践学习记录"><a href="#PyTorch深度学习实践学习记录" class="headerlink" title="PyTorch深度学习实践学习记录"></a>PyTorch深度学习实践学习记录</h1><h2 id="0-配置环境"><a href="#0-配置环境" class="headerlink" title="0 配置环境"></a>0 配置环境</h2><ul>
<li><p>conda环境：’pytorch’  </p>
<pre><code>  conda create -n pytorch python=3.9  
</code></pre>
</li>
<li><p>GPU：NVIDIA GeForce GTX 1050 Ti  </p>
</li>
<li><p>安装cuda  </p>
<pre><code> conda install pytorch==1.10.1 torchvision==0.11.2 torchaudio==0.10.1 cudatoolkit=10.2
</code></pre>
</li>
<li><p>测试一下  </p>
<pre><code>  import torch  
  torch.cuda.is_available()  //成功则返回True
</code></pre>
</li>
<li><p>安装pycharm和jupyter notebook  </p>
</li>
<li><p>dir()和help()函数</p>
</li>
</ul>
<h2 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1 加载数据"></a>1 加载数据</h2><ol>
<li>Dataset  提供一种方式去获取数据及其label</li>
</ol>
<ul>
<li><p>如何获取每一个数据及其label？   </p>
<pre><code>  def __init__(self, root_dir, label_dir)  
  def __getitem__(self, idx):
</code></pre>
</li>
</ul>
<p>三种数据集结构  1.label是文件夹名 2.label在txt文件中  3.label包含在文件名中  </p>
<ul>
<li><p>告诉我们总共有多少的数据？  </p>
<pre><code>  def __len__(self):
      return len(self.img_path_list)
</code></pre>
</li>
</ul>
<ol start="2">
<li><p>Dataloader  为后面的网络提供不同的数据形式  </p>
<pre><code> test_loader = DataLoader(dataset=test_data, batch_size=64，shuffle=True, num_workers=0)

 writer = SummaryWriter(&quot;dataloader_logs&quot;)
 for epoch in range(2):
         step = 0
         for data in test_loader:
                 imgs, targets = data
                 writer.add_images(&quot;epoch: &#123;&#125;&quot;.format(epoch), imgs, step)
                 step = step + 1 
</code></pre>
<p> <img src="https://dt-files.oss-cn-beijing.aliyuncs.com/hexo/20230309132216.png"></p>
</li>
</ol>
<h2 id="2-tensorboard的使用"><a href="#2-tensorboard的使用" class="headerlink" title="2 tensorboard的使用"></a>2 tensorboard的使用</h2><p>启动tensorboard  </p>
<pre><code>    tensorboard --logdir=logs --port=6007
</code></pre>
<p>example：  </p>
<pre><code>    writer = SummaryWriter(&quot;logs&quot;)

    image_path = &quot;dataset/train/ants/0013035.jpg&quot;
    img_PIL = Image.open(image_path)
    img_array = np.array(img_PIL)
    writer.add_image(&quot;train&quot;, img_array, 1, dataformats=&#39;HWC&#39;)
    # y = 2x
    for i in range(100):
    writer.add_scalar(&quot;y=2x&quot;, 2*i, i)
    writer.close()  
</code></pre>
<h2 id="3-transform的使用"><a href="#3-transform的使用" class="headerlink" title="3 transform的使用"></a>3 transform的使用</h2><p>关注输入和输出类型，多看官方文档，关注方法需要的参数  </p>
<ol>
<li><p>ToTensor()</p>
<pre><code> tensor_trans = transforms.ToTensor()
 tensor_img = tensor_trans(img)
</code></pre>
</li>
<li><p>Normalize  </p>
<pre><code> trans_norm = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
 img_norm = trans_norm(tensor_img)  
</code></pre>
</li>
<li><p>Resize </p>
<pre><code> trans_resize = transforms.Resize((256, 256))  
</code></pre>
</li>
<li><p>Compose </p>
<pre><code> trans_resize_2 = transforms.Resize(256)
 trans_compose = transforms.Compose([trans_resize_2, tensor_trans])
 img_resize_2 = trans_compose(img)  
</code></pre>
</li>
<li><p>RandomCrop</p>
<pre><code> trans_random = transforms.RandomCrop(256)
 trans_compose_2 = transforms.Compose([trans_random, tensor_trans])
</code></pre>
</li>
</ol>
<h2 id="4-dataset-和-transform-一起使用"><a href="#4-dataset-和-transform-一起使用" class="headerlink" title="4 dataset 和 transform 一起使用"></a>4 dataset 和 transform 一起使用</h2><pre><code>    dataset_transform = torchvision.transforms.Compose([
            torchvision.transforms.ToTensor() 
            ])
    train_set = torchvision.datasets.CIFAR10(root=&quot;./dataset_CIFAR10&quot;，transform=dataset_transform, train=True, download=True)
    test_set = torchvision.datasets.CIFAR10(root=&quot;./dataset_CIFAR10&quot;, transform=dataset_transform, train=False, download=True)  
</code></pre>
<h2 id="5-Neural-Network"><a href="#5-Neural-Network" class="headerlink" title="5 Neural Network"></a>5 Neural Network</h2><h3 id="1-nn-Module"><a href="#1-nn-Module" class="headerlink" title="1 nn.Module"></a>1 nn.Module</h3><p>Base class for all neural network modules<br>example:</p>
<pre><code>    import torch.nn as nn
    import torch.nn.functional as F

    class Model(nn.Module):
    def __init__(self):
            super().__init__()
            self.conv1 = nn.Conv2d(1, 20, 5)
            self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
            x = F.relu(self.conv1(x))
            return F.relu(self.conv2(x))  
</code></pre>
<h3 id="2-nn-Conv2d"><a href="#2-nn-Conv2d" class="headerlink" title="2 nn.Conv2d"></a>2 nn.Conv2d</h3><p>Parameters:   </p>
<ul>
<li><p>in_channels (int) – Number of channels in the input image  </p>
</li>
<li><p>out_channels (int) – Number of channels produced by the convolution</p>
</li>
<li><p>kernel_size (int or tuple) – Size of the convolving kernel</p>
</li>
<li><p>stride (int or tuple, optional) – Stride of the convolution. Default: 1</p>
</li>
<li><p>padding (int, tuple or str, optional) – Padding added to all four sides of the input. Default: 0</p>
</li>
<li><p>padding_mode (str, optional) – ‘zeros’, ‘reflect’, ‘replicate’ or ‘circular’. Default: ‘zeros’</p>
</li>
<li><p>dilation (int or tuple, optional) – Spacing between kernel elements. Default: 1  空洞卷积</p>
</li>
<li><p>groups (int, optional) – Number of blocked connections from input channels to output channels. Default: 1</p>
</li>
<li><p>bias (bool, optional) – If True, adds a learnable bias to the output. Default: True  </p>
<p><img src="https://dt-files.oss-cn-beijing.aliyuncs.com/hexo/20230319164750.png#pic_center"></p>
</li>
</ul>
<h3 id="3-nn-MaxPool2d"><a href="#3-nn-MaxPool2d" class="headerlink" title="3 nn.MaxPool2d"></a>3 nn.MaxPool2d</h3><p>又叫下采样， nn.MaxUnpool2d 为上采样<br>Parameters:</p>
<ul>
<li><p>kernel_size (Union[int, Tuple[int, int]]) – the size of the window to take a max over</p>
</li>
<li><p>stride (Union[int, Tuple[int, int]]) – the stride of the window. Default <em><strong>value is kernel_size</strong></em></p>
</li>
<li><p>padding (Union[int, Tuple[int, int]]) – Implicit negative infinity padding to be added on both sides</p>
</li>
<li><p>dilation (Union[int, Tuple[int, int]]) – a parameter that controls the stride of elements in the window</p>
</li>
<li><p>return_indices (bool) – if True, will return the max indices along with the outputs. Useful for torch.nn.MaxUnpool2d later</p>
</li>
<li><p>ceil_mode (bool) – when True, will use ceil instead of floor to compute the output shape  </p>
<p><img src="https://dt-files.oss-cn-beijing.aliyuncs.com/hexo/20230319164621.png#pic_center"></p>
</li>
</ul>
<h3 id="4-Non-linear-Activations"><a href="#4-Non-linear-Activations" class="headerlink" title="4 Non-linear Activations"></a>4 Non-linear Activations</h3><ul>
<li><p>nn.ReLU  </p>
</li>
<li><p>nn.Sigmoid<br>效果：</p>
<p><img src="https://dt-files.oss-cn-beijing.aliyuncs.com/hexo/20230320092744.png#pic_center"></p>
</li>
</ul>
<h3 id="5-nn-Sequential"><a href="#5-nn-Sequential" class="headerlink" title="5 nn.Sequential"></a>5 nn.Sequential</h3><p>example:  </p>
<pre><code>    self.model1 = Sequential(
        Conv2d(3, 32, 5, padding=2),
        MaxPool2d(2),
        Conv2d(32, 32, 5, padding=2),
        MaxPool2d(2),
        Conv2d(32, 64, 5, padding=2),
        MaxPool2d(2),
        Flatten(),
        Linear(1024, 64),
        Linear(64, 10)
    )  
</code></pre>
<p>  <img src="https://dt-files.oss-cn-beijing.aliyuncs.com/hexo/20230320101329.png#pic_center"></p>
<h2 id="使用已有模型开发"><a href="#使用已有模型开发" class="headerlink" title="使用已有模型开发"></a>使用已有模型开发</h2><pre><code>    vgg16_false = torchvision.models.vgg16(pretrained=False)
    vgg16_true = torchvision.models.vgg16(pretrained=True)
</code></pre>
<p>vgg16预训练是在ImagNet上，但ImagNetl类别是1000个，Cifar10类别是10个<br>方案1：add_module添加一个线性层  </p>
<pre><code>    vgg16_true.classifier.add_module(&#39;add_linear&#39;, nn.Linear(1000, 10))
</code></pre>
<p>方案2：直接修改某一层</p>
<pre><code>    vgg16_false.classifier[6] = nn.Linear(4096, 10)
</code></pre>
<p>模型的保存与导入（两种）    </p>
<ol>
<li><p>   torch.save(vgg16_false, “vgg16_method1.pth”)<br>   model &#x3D; torch.load(“vgg16_method1.pth”)</p>
</li>
<li><p>(recommend) smaller  通过字典形式存储参数</p>
<pre><code>torch.save(vgg16_false.state_dict(), &quot;vgg16_method2.pth&quot;)   
vgg16_false.load_state_dict(torch.load(&quot;vgg16_method2.pth&quot;))
</code></pre>
</li>
</ol>
<h2 id="完整的训练流程（套路）"><a href="#完整的训练流程（套路）" class="headerlink" title="完整的训练流程（套路）"></a>完整的训练流程（套路）</h2><ol>
<li><p>准备数据集</p>
</li>
<li><p>dataloader加载数据集</p>
</li>
<li><p>搭建网络模型</p>
</li>
<li><p>创建网络模型实例</p>
</li>
<li><p>定义损失函数</p>
</li>
<li><p>定义优化器</p>
</li>
<li><p>设置网络训练的参数</p>
</li>
<li><p>开始训练</p>
</li>
<li><p>验证模型</p>
</li>
<li><p>最后保存模型</p>
</li>
<li><p>tensorboard训练结果展示</p>
<pre><code># 准备训练数据集
train_data = torchvision.datasets.CIFAR10(root=&quot;./dataset_CIFAR10&quot;, train=True, transform=torchvision.transforms.ToTensor(),download=True)

# 准备训练数据集
test_data = torchvision.datasets.CIFAR10(root=&quot;./dataset_CIFAR10&quot;, train=False, transform=torchvision.transforms.ToTensor(),download=True)
print(&quot;训练数据集的长度为：&#123;&#125;&quot;.format(len(train_data)))

# 利用DataLoader来加载数据集
train_dataloader = DataLoader(train_data, batch_size=64)
test_dataloader = DataLoader(train_data, batch_size=64)

# 创建网络模型
model = Model()

# 损失函数
loss_fn = nn.CrossEntropyLoss()

# 优化器
learning_rate = 1e-2
optimizer =  torch.optim.SGD(model.parameters(), lr=learning_rate)

# 设置训练网络的一些参数
# 记录训练的次数
total_train_step = 0
# 记录测试的次数
total_test_step = 0
# 训练的轮数
epoch = 10

# 添加tensorboard
writer = SummaryWriter(&quot;train_logs&quot;)

for i in range(epoch):
print(&quot;--------第 &#123;&#125; 轮训练开始--------&quot;.format(i+1))
# 训练步骤
# model.train()  # 适用于有dropout层，Norm层
for data in train_dataloader:
        imgs, targets = data
        outputs = model(imgs)
        loss = loss_fn(outputs, targets)
        # 优化器优化模型
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_train_step = total_train_step + 1
        if total_train_step % 100 == 0:
        print(&quot;训练次数：&#123;&#125;，loss:&#123;&#125;&quot;.format(total_train_step, loss.item()))
        writer.add_scalar(&quot;train_loss&quot;, loss.item(), total_train_step)

# 测试步骤
# model.eval()  # 适用于有dropout层，Norm层
total_test_loss = 0.0
with torch.no_grad():
        for data in test_dataloader:
        imgs, targets = data
        outputs = model(imgs)
        loss = loss_fn(outputs, targets)
        total_test_loss += loss.item()
        accuracy = (outputs.argmax(1) == targets).sum()
        total_accuracy = total_accuracy + accuracy
print(&quot;整体测试集上的Loss：&#123;&#125;&quot;.format(total_test_loss))
print(&quot;整体测试集上的accuracy：&#123;&#125;&quot;.format(total_accuracy/len(test_data)))
writer.add_scalar(&quot;test_loss&quot;, total_test_loss, total_test_step)
writer.add_scalar(&quot;test_accuracy&quot;, total_accuracy/len(test_data), total_test_step)
total_train_step += 1

# 保存模型
# torch.save(model, &quot;model_&#123;&#125;.pth&quot;.format(i))
# print(&quot;模型已保存&quot;)
writer.close()
</code></pre>
</li>
</ol>
<h2 id="使用GPU训练"><a href="#使用GPU训练" class="headerlink" title="使用GPU训练"></a>使用GPU训练</h2><p>对模型、损失函数、要训练和验证数据处理，两种方式：  </p>
<ol>
<li>.cuda() </li>
<li>先定义device &#x3D; torch.device(“cuda”)，然后对模型、损失函数、数据使用.to(device)<br>可使用google.colab使用免费的计算资源</li>
</ol>
<h2 id="验证的流程"><a href="#验证的流程" class="headerlink" title="验证的流程"></a>验证的流程</h2><pre><code>    image_path = &quot;&quot;
    image = Image.open(image_path)

    transform = torchvision.transforms.Compose([torchvision.transforms.Resize((32, 32)),
                                            torchvision.transforms.ToTensor()])

    image = transform(image)

    # 载入网络模型
    # 如果是gpu上训练的结果在cpu上载入，要加map_location=torch.device(&#39;cpu&#39;)
    model = torch.load(&quot;model_29_gpu.pth&quot;, map_location=torch.device(&#39;cpu&#39;))

    image = torch.reshape(image, (1, 3, 32, 32))
    model.eval()
    with torch.no_grad():
    output = model(image)
    print(output)
    print(output.argmax(1))
</code></pre>

        
            <div id="toc-article">
                
  <div class="widget-wrap" id="toc-wrap">
    <h3 class="widget-title"><i class="fa fa-toc"></i> Contents</h3>
    <div class="widget">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#PyTorch%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95"><span class="toc-text">PyTorch深度学习实践学习记录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#0-%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83"><span class="toc-text">0 配置环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-text">1 加载数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-tensorboard%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">2 tensorboard的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-transform%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-text">3 transform的使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-dataset-%E5%92%8C-transform-%E4%B8%80%E8%B5%B7%E4%BD%BF%E7%94%A8"><span class="toc-text">4 dataset 和 transform 一起使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-Neural-Network"><span class="toc-text">5 Neural Network</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-nn-Module"><span class="toc-text">1 nn.Module</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-nn-Conv2d"><span class="toc-text">2 nn.Conv2d</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-nn-MaxPool2d"><span class="toc-text">3 nn.MaxPool2d</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-Non-linear-Activations"><span class="toc-text">4 Non-linear Activations</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-nn-Sequential"><span class="toc-text">5 nn.Sequential</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%B7%B2%E6%9C%89%E6%A8%A1%E5%9E%8B%E5%BC%80%E5%8F%91"><span class="toc-text">使用已有模型开发</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B%EF%BC%88%E5%A5%97%E8%B7%AF%EF%BC%89"><span class="toc-text">完整的训练流程（套路）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8GPU%E8%AE%AD%E7%BB%83"><span class="toc-text">使用GPU训练</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81%E7%9A%84%E6%B5%81%E7%A8%8B"><span class="toc-text">验证的流程</span></a></li></ol></li></ol>
    </div>
  </div>


            </div>
        
        
          <blockquote id="copyright">
              <p>Original link: <a href="http://example.com/2023/02/28/pytorch-study/">http://example.com/2023/02/28/pytorch-study/</a></p>
              <p>Copyright Notice: 转载请注明出处.</p>
          </blockquote>
        
      
    </div>
    <footer class="article-footer">
      
        <div class="article-tag-wrap">
          

          
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PyTorch/" rel="tag">PyTorch</a></li></ul>

          
    <div class="social-share">
      <span>Share:</span>
    </div>



        </div>
      
      
        
<nav id="article-nav">
  
    <a href="/2023/02/24/Knowledge-Enhanced-Prompt-Learning/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">older</strong>
      <div class="article-nav-title">
        
          Knowledge-Enhanced Prompt Learning
        
      </div>
    </a>
  
  
    <a href="/2023/02/28/prompt-learning/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">newer</strong>
      <div class="article-nav-title">
        
          prompt learning
        
      </div>
    </a>
  
</nav>

      
      
        








      
    </footer>
  </div>
</article>
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-posts"></i> Recent</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2024/04/18/Java-gulimall/">Java-gulimall</a>
          </li>
        
          <li>
            <a href="/2024/03/11/offer-JVM/">offer-JVM</a>
          </li>
        
          <li>
            <a href="/2023/08/29/offer-SSM/">offer-SSM</a>
          </li>
        
          <li>
            <a href="/2023/07/18/Prompt-Engineering/">Prompt Engineering</a>
          </li>
        
          <li>
            <a href="/2023/07/10/offer-redis6/">offer-redis6</a>
          </li>
        
      </ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-tag"></i> Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CRS/" style="font-size: 20px;">CRS</a> <a href="/tags/ChatGPT/" style="font-size: 20px;">ChatGPT</a> <a href="/tags/Dialog/" style="font-size: 10px;">Dialog</a> <a href="/tags/JAVA/" style="font-size: 15px;">JAVA</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a> <a href="/tags/LLM/" style="font-size: 10px;">LLM</a> <a href="/tags/PyTorch/" style="font-size: 10px;">PyTorch</a> <a href="/tags/Redis/" style="font-size: 10px;">Redis</a> <a href="/tags/SSM/" style="font-size: 10px;">SSM</a> <a href="/tags/Web/" style="font-size: 10px;">Web</a> <a href="/tags/flask-vue-mysql/" style="font-size: 10px;">flask,vue,mysql</a>
    </div>
  </div>

  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-archive"></i> Archive</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/">2024年</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/">2023年</a><span class="archive-list-count">18</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-tag"></i> Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CRS/" rel="tag">CRS</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ChatGPT/" rel="tag">ChatGPT</a><span class="tag-list-count">3</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Dialog/" rel="tag">Dialog</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/JAVA/" rel="tag">JAVA</a><span class="tag-list-count">2</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Java/" rel="tag">Java</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/LLM/" rel="tag">LLM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PyTorch/" rel="tag">PyTorch</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Redis/" rel="tag">Redis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/SSM/" rel="tag">SSM</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Web/" rel="tag">Web</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flask-vue-mysql/" rel="tag">flask,vue,mysql</a><span class="tag-list-count">1</span></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title"><i class="fa fa-link"></i> Blogroll</h3>
    <div class="widget">
      <ul>
      
        <li>
          <a target="_blank" rel="noopener" href="http://www.example1.com/">site-name1</a>
        </li>
      
        <li>
          <a target="_blank" rel="noopener" href="http://www.example2.com/">site-name2</a>
        </li>
      
        <li>
          <a target="_blank" rel="noopener" href="http://www.example3.com/">site-name3</a>
        </li>
      
      </ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <a id="totop" href="#top"></a>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      <p>
        <a href="/sitemap.xml">Site Map</a>
        <span> | </span><a href="/atom.xml">Subscribe to this site</a>
        <span> | </span><a href="/about/">Contact the blogger</a>
      </p>
      
        <p>
          <i class="fa fa-visitors"></i>
          <i id="busuanzi_container_site_uv"><i id="busuanzi_value_site_uv"></i></i>
          ，
          <i class="fa fa-views"></i>
          <i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>
        </p>
      
      <p>
        <span>Copyright &copy; 2024 JupiterTop.</span>
        <span>Theme by <a href="https://github.com/chaooo/hexo-theme-BlueLake/" target="_blank">BlueLake.</a></span>
        <span>Powered by <a href="https://hexo.io/" target="_blank">Hexo.</a></span>
      </p>
    </div>
  </div>
</footer>


    </div>
  </div>
  
<script src="/js/jquery-3.4.1.min.js"></script>


<script src="/js/search.json.js"></script>


  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>






  
<script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  
    
<script src="/localshare/js/social-share.js"></script>

    
<script src="/localshare/js/qrcode.js"></script>

  
  



  

  

  

  

  

  

  

  
  





</body>
</html>